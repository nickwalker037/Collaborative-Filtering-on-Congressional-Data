{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import re, math\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "from __future__ import print_function\n",
    "import annoy\n",
    "from implicit import alternating_least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/nickwalker/Desktop/Coding/Python/Congress Data/bills_with_sponsor.csv\")\n",
    "df1 = pd.read_csv(\"/Users/nickwalker/Desktop/Coding/Python/Congress Data/bill_cosponsorship_1.csv\")\n",
    "df2 = pd.read_csv(\"/Users/nickwalker/Desktop/Coding/Python/Congress Data/bill_details.csv\")\n",
    "df3 = pd.DataFrame(df1)\n",
    "df4 = pd.DataFrame(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>bill_number</th>\n",
       "      <th>date</th>\n",
       "      <th>withdrawn_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K000188</td>\n",
       "      <td>H.CON.RES.10</td>\n",
       "      <td>1/13/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N000015</td>\n",
       "      <td>H.CON.RES.10</td>\n",
       "      <td>1/23/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T000462</td>\n",
       "      <td>H.CON.RES.10</td>\n",
       "      <td>1/23/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P000593</td>\n",
       "      <td>H.CON.RES.10</td>\n",
       "      <td>1/31/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J000290</td>\n",
       "      <td>H.CON.RES.10</td>\n",
       "      <td>2/7/2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  member_id   bill_number       date  withdrawn_date\n",
       "0   K000188  H.CON.RES.10  1/13/2017               1\n",
       "1   N000015  H.CON.RES.10  1/23/2017               1\n",
       "2   T000462  H.CON.RES.10  1/23/2017               1\n",
       "3   P000593  H.CON.RES.10  1/31/2017               1\n",
       "4   J000290  H.CON.RES.10   2/7/2017               1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeVector(self, wordString):\n",
    "        \"\"\" @pre: unique(vectorIndex) \"\"\"\n",
    "\n",
    "        #Initialise vector with 0's\n",
    "        vector = [0] * len(self.vectorKeywordIndex)\n",
    "        wordList = self.parser.tokenise(wordString)\n",
    "        wordList = self.parser.removeStopWords(wordList)\n",
    "        for word in wordList:\n",
    "                vector[self.vectorKeywordIndex[word]] += 1; #Use simple Term Count Model\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\" Reads in the last.fm dataset, and returns a tuple of a pandas dataframe\n",
    "    and a sparse matrix of artist/user/playcount \"\"\"\n",
    "    # read in triples of user/artist/playcount from the input dataset\n",
    "    data = pd.read_table(filename,\n",
    "                        usecols=[0, 1, 3],\n",
    "                        names=['member_id', 'bill_number', 'plays'])\n",
    "\n",
    "    # map each artist and user to a unique numeric value\n",
    "    data['member_id'] = data['member_id'].astype(\"category\")\n",
    "    data['bill_number'] = data['bill_number'].astype(\"category\")\n",
    "\n",
    "    # create a sparse matrix of all the users/plays\n",
    "    plays = coo_matrix((data['plays'].astype(float),\n",
    "                       (data['member_id'].cat.codes.copy(),\n",
    "                        data['bill_number'].cat.codes.copy())))\n",
    "\n",
    "    return data, plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#df3.iloc[:,[0,2]]\\ndef read_data(filename):\\n    df1 = pd.read_csv(filename)\\n    df = pd.DataFrame(df1)\\n    df = df.iloc[:,[0,1]]\\n    \\n    df[\\'member_id\\'] = df[\\'member_id\\'].astype(\"category\")\\n    df[\\'bill_number\\'] = df[\\'bill_number\\'].astype(\"category\")\\n    \\n    out = coo_matrix((df[\\'member_id\\'].cat.codes.copy(),\\n                     df[\\'bill_number\\'].cat.codes.copy()))\\n    return out'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#df3.iloc[:,[0,2]]\n",
    "def read_data(filename):\n",
    "    df1 = pd.read_csv(filename)\n",
    "    df = pd.DataFrame(df1)\n",
    "    df = df.iloc[:,[0,1]]\n",
    "    \n",
    "    df['member_id'] = df['member_id'].astype(\"category\")\n",
    "    df['bill_number'] = df['bill_number'].astype(\"category\")\n",
    "    \n",
    "    out = coo_matrix((df['member_id'].cat.codes.copy(),\n",
    "                     df['bill_number'].cat.codes.copy()))\n",
    "    return out\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> BM25 Weighting </h2>\n",
    "- BM - Best Matching\n",
    "- Is one of the best probablistic weighting schemes\n",
    "- is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document alt text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm25_weight(X, K1=3000, B=0.8):\n",
    "    \"\"\" Weighs each row of the sparse matrix of the data by BM25 weighting \"\"\"\n",
    "    # calculate idf per term (user)\n",
    "    X = coo_matrix(X)\n",
    "    N = X.shape[0]\n",
    "    idf = np.log(float(N) / (1 + np.bincount(X.col)))\n",
    "    \n",
    "    # calculate length_norm per document \n",
    "    row_sums = np.ravel(X.sum(axis=1))\n",
    "    avg_length = row_sums.mean()\n",
    "    length_norm = (1.0 - B) + B * row_sums / avg_length\n",
    "    \n",
    "    # weight matrix rows by BM25\n",
    "    X.data = X.data * (K1 + 1.0) / (K1 * length_norm[X.row] + X.data) * idf[X.col]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TopRelated(object):\n",
    "    def __init__(self, congress_factors):\n",
    "        # fully normalize congress_factors, so we can compare with only the dot product\n",
    "        norms = np.linalg.norm(congress_factors, axis=-1)\n",
    "        self.factors = congress_factors / norms[:, np.newaxis]\n",
    "        \n",
    "    def get_related(self, congressID, N=10):\n",
    "        scores = self.factors.dot(self.factors[congressID])\n",
    "        best = numpy.argpartition(scores, -N)[-N:]\n",
    "        return sorted(zip(best, scores[best]), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ApproximateTopRelated(object):\n",
    "    def __init__(self, congress_factors, treecount=20):\n",
    "        index = annoy.AnnoyIndex(congress_factors.shape[1], 'angular')\n",
    "        for i, row in enumerate(congress_factors):\n",
    "            index.add_item(i, row)\n",
    "        index.build(treecount)\n",
    "        self.index = index\n",
    "\n",
    "    def get_related(self, congressID, N=5):\n",
    "        neighbors = self.index.get_nns_by_item(congressID, N)\n",
    "        return sorted(((other, 1 - self.index.get_distance(congressID, other))\n",
    "                      for other in neighbors), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_similar_members(input_filename, output_filename,\n",
    "                              factors=30, regularization=0.01,\n",
    "                              iterations=40,\n",
    "                              exact=False, trees=20,\n",
    "                              use_native=True,\n",
    "                              dtype=np.float64,\n",
    "                              cg=False):\n",
    "    print(\"Calculating similar congress members. This might take a while\")\n",
    "    print(\"reading data from %s\", input_filename)\n",
    "    start = time.time()\n",
    "    df, plays = read_data(input_filename)\n",
    "    print(\"read data file in %s\", time.time() - start)\n",
    "\n",
    "    print(\"weighting matrix by bm25\")\n",
    "    weighted = bm25_weight(plays)\n",
    "\n",
    "    print(\"calculating factors\")\n",
    "    start = time.time()\n",
    "    congress_factors, user_factors = alternating_least_squares(weighted,\n",
    "                                                             factors=factors,\n",
    "                                                             regularization=regularization,\n",
    "                                                             iterations=iterations,\n",
    "                                                             use_native=use_native,\n",
    "                                                             dtype=dtype,\n",
    "                                                             use_cg=cg)\n",
    "    print(\"calculated factors in %s\", time.time() - start)\n",
    "    \n",
    "    # write out artists by popularity\n",
    "    print(\"calculating top congress members\")\n",
    "    user_count = df.groupby('member_id').size()\n",
    "    members = dict(enumerate(df['member_id'].cat.categories))\n",
    "    to_generate = sorted(list(members), key=lambda x: -user_count[x])\n",
    "    \n",
    "    \n",
    "    print(congress_factors)\n",
    "    if exact:\n",
    "        calc = TopRelated(congress_factors)\n",
    "    else:\n",
    "        calc = ApproximateTopRelated(congress_factors, trees)\n",
    "\n",
    "    print(\"writing top related to %s\", output_filename)\n",
    "    with open(output_filename, \"w\") as o:\n",
    "        for congressID in to_generate:\n",
    "            member = members[congressID]\n",
    "            for other, score in calc.get_related(congressID):\n",
    "                o.write(\"%s\\t%s\\t%s\\n\" % (member, members[other], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calculate_similar_members(\"/Users/nickwalker/Desktop/Coding/Python/Congress Data/bill_cosponsorship_1.csv\", 'Congress Data/billPerson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
